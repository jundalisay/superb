---
title:  "The Mathematical Electricians Of The Mid-19th Century"
heading:  "Chapter 7"
weight: 50
author: Edmund Taylor Whittaker
image:  "/covers/history.jpg"
description: ""
---



While Faraday was engaged in discovering the laws of induced currents in his own way, by use of the conception of lines of force, his contemporary Franz Neumann was attacking the same problem from a different point of view. Neumann preferred to take Ampère as his model; and in 1845 published a memoir,[1] in which the laws of induction of currents were deduced by the help of Ampère's analysis.

Among the assumptions on which Neumann based his work was a rule which had been formulated, not long after Faraday's original discovery, by Ennil Lenz,[2] and which may be enunciated as follows: when a conducting circuit is moved in a magnetic field, the induced current flows in such a direction that the ponderomotive forces on it tend to oppose the motion,

Let ds denote an element of the circuit which is in motion, and let Cds denote the component, taken in the direction of motion, of the ponderomotive force exerted by the inducing current on ds, when the latter is carrying unit current; so that the value of C is known from Ampère's theory. Then Lenz's rule requires that the product of O into the strength of the induced current should be negative. Neumann assumed that this is because it consists of a negative coefficient multiplying the square of C; that is, he assumed the induced electro- motive force to be proportional to C. He further assumed it to be proportional to the velocity v of the motion, and thus obtained for the electromotive force induced in ds the expression

where ε denotes a constant coefficient. By aid of this formula, ​in the earlier part[3] of the memoir, he calculated the induced currents in various particular cases.

But having arrived at the formulae in this way, Neumann noticed[4] a peculiarity in them which suggested a totally different method of treating the subject. In fact, on examining the expression for the current induced in a circuit which is in motion in the field due to a magnet, it appeared that this induced current depends only on the alteration caused by the motion in the value of a certain function; and, moreover, that this function is no other than the potential of the ponderomotive forces which, according to Ampère's theory, act between the circuit, supposed traversed by unit current, and the magnet.

Accordingly, Neumann now proposed to reconstruct his theory by taking this potential function as the foundation.

The nature of Neumann's potential, and its connexion with Faraday's theory, will be understood from the following considerations:—

The potential energy of a magnetic molecule M in a field of magnetic intensity B is (B.M); and therefore the potential energy of a current i flowing in a circuit's in this field is

�
∬
�
′
(
�
.
�
�
)
{\displaystyle i\iint _{S'}(\mathbf {B.} d\mathbf {S} )},

where S denotes a diaphragm bounded by the circuit s; as is seen at once on replacing the circuit by its equivalent magnetic shell S. If the field B be produced by a current i′ flowing in a circuit s′, we have, by the formula of Biot and Savart,

�
=
�
′
∫
�
′
[
�
�
′
.
�
]
�
3
 
=
�
′
∫
�
′
c
u
r
l
 
�
�
′
�
.
{\displaystyle {\begin{matrix}\mathbf {B} &=&i^{\prime }\int _{s^{\prime }}{\frac {[\mathbf {ds^{\prime }.r} ]}{r^{3}}}\\\ &=&i^{\prime }\int _{s^{\prime }}\mathrm {curl} \ {\frac {\mathbf {ds^{\prime }} }{r}}.\end{matrix}}}

​Hence, the mutual potential energy of the two currents is
�
�
′
∫
�
′
∬
�
(
c
u
r
l
 
�
�
′
�
.
�
�
)
{\displaystyle ii^{\prime }\int \limits _{s^{\prime }}\iint \limits _{S}\left(\mathrm {curl} \ {\frac {\mathbf {ds^{\prime }} }{r}}\mathbf {.dS} \right)},

which by Stokes's transformation may be written in the form

�
�
′
∫
�
∫
�
′
(
�
�
.
�
�
′
)
�
{\displaystyle ii^{\prime }\int _{s}\int _{s^{\prime }}{\frac {(\mathbf {ds.ds^{\prime }} )}{r}}}.

This expression represents the amount of mechanical work which must be performed against the electro-dynamic ponderomotive forces, in order to separate the two circuits to an infinite distance apart, when the current-strengths are maintained unaltered.

The above potential function has been obtained by considering the ponderomotive forces; but it can now be connected with Faraday's theory of induction of currents. interpreting the expression

∬
�
(
�
.
�
�
)
{\displaystyle \iint \limits _{S}(\mathbf {B.dS} )}

in terms of lines of force, we see that the potential function represents the product of i into the number of unit-lines of magnetic force due to s′, which pass through the gap formed by the circuit s; and since by Faraday's law the currents induced in s depend entirely on the variation in the number of these lines, it is evident that the potential function supplies all that is needed for the analytical treatment of the induced currents. This was Neumann's discovery.

The electromotive force induced in a circuit s by the motion of other circuits s′, carrying currents i′, is thus proportional to the time-rate of variation of the potential

�
′
∫
�
∫
�
′
�
�
.
�
�
′
�
{\displaystyle i^{\prime }\int _{s}\int _{s^{\prime }}{\frac {\mathbf {ds.ds^{\prime }} }{r}}};

so that if we denote by a the vector

�
′
∫
�
′
�
�
′
�
{\displaystyle i^{\prime }\int _{s^{\prime }}{\frac {\mathbf {ds^{\prime }} }{r}}},

​which, of course, is a function of the position of the element ds from which r is measured, then the electromotive force induced in any circuit-element ds by any alteration in the currents which give rise to a is
(
�
˙
.
�
�
)
{\displaystyle (\mathbf {{\dot {a}}.ds} )}.

The induction of currents is therefore governed by the vector a; this, which is generally known as the vector-potential, has from Neumann's time onwards played a great part in electrical theory. It may be readily interpreted in terms of Faraday's conceptions; for (a.ds) represents the total number of unit lines of magnetic force which have passed across the line-element ds prior to the instant t. The vector-potential may in fact be regarded as the analytical measure of Faraday's electrotonic state.[5]

While Neumann was endeavouring to comprehend the laws of induced currents in an extended form of Ampère's theory, another investigator was attempting a still more ambitious project: 110 less than that of uniting electrodynamics into a coherent whole with electrostatics.

Wilhelm Weber (b. 1804, d. 1890) was in the earlier part of his scientific career a friend and colleague of Gauss at Göttingen. In 1837, however, he became involved in political trouble. The union of Hanover with the British Empire, which had subsisted since the accession of the Hanoverian dynasty to the British throne, was in that year dissolved by the operation of the Salic law; the Princess Victoria succeeded to the crown of England, and her uncle Ernest-Augustus to that of Hanover. The new king, who was a pronounced reactionary, revoked the free constitution which the Hanoverians had for some time enjoyed; and Weber, who took a prominent part in opposing this action, was deprived of his professorship. From 1843 to 1849, when his principal theoretical researches in electricity were made, he occupied a chair in the University of Leipzig.

The theory of Weber was in its origin closely connected with the work of another Leipzig Professor, Fechner, who in 1845[6] introduced certain assumptions regarding the nature of ​electric currents. Fechner supposed every current to consist in a streaming of electric charges, the vitreous charges travelling in one direction, and the resinous charges, equal to them in magnitude and number, travelling in the opposite direction with equal velocity. He further supposed that like charges attract each other when they are moving parallel to the same direction, while unlike charges attract when they are moving in opposite directions. On these assumptions he succeeded in bringing Faraday's induction effects into connexion with Ampère's laws of electrodynamics.

In 1846 Weber,[7] adopting the same assumptions as Fechner, analysed the phenomena in the following way:—

The formula of Ampère for the ponderomotive force between two elements ds, ds′ of currents i, i′, may be written

�
=
�
�
′
 
�
�
 
�
�
′
 
(
2
�
�
2
�
�
�
 
�
�
′
−
1
�
3
�
�
�
�
�
�
�
�
′
)
{\displaystyle F=ii^{\prime }\ ds\ ds^{\prime }\ \left({\frac {2}{r}}{\frac {d^{2}r}{ds\ ds^{\prime }}}-{\frac {1}{r^{3}}}{\frac {dr}{ds}}{\frac {dr}{ds^{\prime }}}\right)}.

Suppose now that λ units of vitreous electricity are contained in unit length of the wire s, and are moving with velocity u; and that an equal quantity of resinous electricity is moving with velocity u in the opposite direction; so that

�
=
2
�
�
{\displaystyle i=2\lambda u}.

Let λ, u′, denote the corresponding quantities for the other current; and let the suffix 1, be taken to refer to the action between the positive charges in the two wires, the suffix 2, to the action between the positive charge in s and the negative charge in s′, the suffix 3, to the action between the negative charge in s and the positive charge in s′, and the suffix 4 to the action between the negative charges in the two wires. Then we have

(
�
�
�
�
)
1
=
�
�
�
�
�
+
�
′
�
�
�
�
′{\displaystyle \left({\frac {dr}{dt}}\right)_{1}=u{\frac {dr}{ds}}+u^{\prime }{\frac {dr}{ds^{\prime }}}},

​and
(
�
�
2
�
�
�
2
)
1
=
�
2
�
2
�
�
�
2
+
2
�
�
′
�
2
�
�
�
 
�
�
′
+
�
′
2
�
2
�
�
�
′
2
{\displaystyle \left(r{\frac {d^{2}r}{dt^{2}}}\right)_{1}=u^{2}{\frac {d^{2}r}{ds^{2}}}+2uu^{\prime }{\frac {d^{2}r}{ds\ ds^{\prime }}}+{u^{\prime }}^{2}{\frac {d^{2}r}{{ds^{\prime }}^{2}}}}.

By aid of these and the similar equations with the suffixes 2, 3, 4 the equation for the ponderomotive force may be transformed into the equation

�
=
�
�
′
 
�
�
 
�
�
′
�
2
{
(
�
�
2
�
�
�
2
)
1
(
�
�
2
�
�
�
2
)
2
(
�
�
2
�
�
�
2
)
3
+
(
�
�
2
�
�
�
2
)
4
−
1
2
(
�
�
�
�
�
)
1
2
+
1
2
(
�
�
�
�
�
)
2
2
+
1
2
(
�
�
�
�
�
)
3
2
−
1
2
(
�
�
�
�
�
)
4
2
{\displaystyle F={\frac {\lambda \lambda ^{\prime }\ ds\ ds^{\prime }}{r^{2}}}{\begin{cases}\left(r{\frac {d^{2}r}{dt^{2}}}\right)_{1}\left(r{\frac {d^{2}r}{dt^{2}}}\right)_{2}\left(r{\frac {d^{2}r}{dt^{2}}}\right)_{3}+\left(r{\frac {d^{2}r}{dt^{2}}}\right)_{4}\\-{\frac {1}{2}}\left(r{\frac {dr}{dt}}\right)_{1}^{2}+{\frac {1}{2}}\left(r{\frac {dr}{dt}}\right)_{2}^{2}+{\frac {1}{2}}\left(r{\frac {dr}{dt}}\right)_{3}^{2}-{\frac {1}{2}}\left(r{\frac {dr}{dt}}\right)_{4}^{2}\end{cases}}}.

But this is the equation which we should have obtained had we set out from the following assumptions: that the ponderomotive force between two current-elements is the resultant of the force between the positive charge in ds and the positive charge in ds′, of the force between the positive charge in ds and the negative charge in ds′, etc.; and that any two electrified particles of charges e and e′, whose distance apart is r, repel each other with a force of magnitude

�
�
′
�
2
{
�
�
2
�
�
�
2
−
1
2
(
�
�
�
�
)
2
}
{\displaystyle {\frac {ee^{\prime }}{r^{2}}}\left\{r{\frac {d^{2}r}{dt^{2}}}-{\frac {1}{2}}\left({\frac {dr}{dt}}\right)^{2}\right\}}.

Two such charges would, of course, also cxert on each other an electrostatic repulsion, whose magnitude in these units would be ee′c2/r2, where c denotes a constant[8] of the dimensions of a velocity, whose value is approximately 3 x 1010 cm./sec. So that on these assumptions the total repellent force would be

�
�
′
�
2
�
2
(
1
+
�
�
¨
�
2
−
�
˙
2
2
�
2
)
{\displaystyle {\frac {ee^{\prime }c^{2}}{r^{2}}}\left(1+{\frac {r{\ddot {r}}}{c^{2}}}-{\frac {{\dot {r}}^{2}}{2c^{2}}}\right)}.

​This expression for the force between two electric charges was taken by Weber as the basis of his theory. Weber's is the first of the electron-theories—a name given to any theory which attributes the phenomena of electrodynamics to the agency of moving electric charges, the forces on which depend not only on the position of the charges (as in electrostatics), but also on their velocity.

The latter feature of Weber's theory led its earliest critics to deny that his law of force could be reconciled with the principle of conservation of energy. They were, however, mistaken on this point, as may be seen from the following considerations. The above expression for the force between two charges may be written in the form

−
�
�
�
�
�
+
�
�
�
(
∂
�
∂
�
˙
)
{\displaystyle -{\frac {dll}{dr}}+{\frac {d}{dt}}\left({\frac {\partial U}{\partial {\dot {r}}}}\right)},

where U denotes the expression

�
�
′
�
2
�
(
1
+
�
˙
2
2
�
2
)
2
{\displaystyle {\frac {ee^{\prime }c^{2}}{r}}\left(1+{\frac {{\dot {r}}^{2}}{2c^{2}}}\right)^{2}}.

Consider now two material particles at distance r apart, whose mechanical kinetic energy is T, and whose mechanical potential energy is V, and which carry charges e and e′. The equations of motion of these particles will be exactly the same as the equations of motion of a dynamical system for which the kinetic energy is

�
−
�
�
′
�
˙
2
2
�
{\displaystyle T-{\frac {ee^{\prime }{\dot {r}}^{2}}{2r}}},

and the potential energy is

�
+
�
�
′
�
2
�
{\displaystyle V+{\frac {ee^{\prime }c^{2}}{r}}}.

To such a system the principle of conservation of energy may be applied: the equation of energy is, in fact,

�
+
�
−
1
2
�
�
�
′
�
˙
2
+
�
�
′
�
2
�
=
 
c
o
n
s
t
a
n
t
{\displaystyle T+V-{\frac {1}{2r}}ee^{\prime }{\dot {r}}^{2}+{\frac {ee^{\prime }c^{2}}{r}}=\ \mathrm {constant} }[errata 1].

​The first objection made to Weber's theory is thus disposed of; but another and more serious one now presents itself. The occurrence of the negative sign with the term 
−
�
�
′
�
˙
2
/
2
�
{\displaystyle -ee^{\prime }{\dot {r}}^{2}/2r} implies that a charge behaves somewhat as if its mass were negative, so that in certain circumstances its velocity might increase indefinitely under the action of a force opposed to the motion. This is one of the vulnerable points of Weber's theory, and has been the object of much criticism. In fact,[9] suppose that one charged particle of mass μ is free to move, and that the other charges are spread uniformly over the surface of a hollow spherical insulator in which the particle is enclosed. The equation of conservation of energy is

1
2
(
�
−
�
�
)
�
2
+
�
=
{\displaystyle {\tfrac {1}{2}}(\mu -ep)v^{2}+V=} constant,

where e denotes the charge of the particle, v its velocity, V its potential energy with respect to the mechanical forces which act on it, and p denotes the quantity

∬
�
�
cos
2
⁡
(
�
.
�
^
)
�
�
{\displaystyle \iint {\frac {\sigma }{r}}\cos ^{2}({\hat {v.r}})dS},

where the integration is taken over the sphere, and where σ denotes the surface-density; p is independent of the position of the particle μ within the sphere. If now the electric charge on the sphere is so great that ep is greater than μ, then v2 and V must increase and diminish together, which is evidently absurd.

Leaving this objection unanswered, we proceed to show how Weber's law of force between electrons leads to the formulae for the induction of currents.

The mutual energy of two moving charges is

�
�
′
�
2
�
(
1
−
�
˙
2
2
�
2
)
{\displaystyle {\frac {ee^{\prime }c^{2}}{r}}\left(1-{\frac {{\dot {r}}^{2}}{2c^{2}}}\right)},

or
�
�
′
�
2
�
[
1
−
{
(
�
.
�
′
)
−
(
�
.
�
)
}
2
2
�
2
�
2
]
{\displaystyle {\frac {ee^{\prime }c^{2}}{r}}\left[1-{\frac {\{(\mathbf {r.v^{\prime }} )-(\mathbf {r.v} )\}^{2}}{2c^{2}r^{2}}}\right]},
where v and v′ denote the velocities of the charges; so that the ​mutual energy of two current-elements containing charges e, e′ respectively of each kind of electricity, is

�
�
′
�
2
2
�
3
[
−
{
(
�
.
�
′
)
−
(
�
.
�
)
}
2
+
{
(
�
.
�
′
)
+
(
�
.
�
)
}
2
+
{
−
(
�
.
�
′
)
−
(
�
.
�
)
}
2
−
{
(
−
�
.
�
′
)
+
(
�
.
�
)
}
2
]
{\displaystyle {\frac {ee^{\prime }c^{2}}{2r^{3}}}[-\{(\mathbf {r.v^{\prime }} )-(\mathbf {r.v} )\}^{2}+\{(\mathbf {r.v^{\prime }} )+(\mathbf {r.v} )\}^{2}+\{-(\mathbf {r.v^{\prime }} )-(\mathbf {r.v} )\}^{2}-\{(\mathbf {-r.v^{\prime }} )+(\mathbf {r.v} )\}^{2}]},

or
4
�
�
′
(
�
.
�
′
)
(
�
.
�
)
�
3
{\displaystyle {\frac {4ee^{\prime }(\mathbf {r.v^{\prime }} )(\mathbf {r.v} )}{r^{3}}}}.
If ds, ds′ denote the lengths of the elements, and i, i′ the currents in them, we have

�
�
�
=
2
�
�
,
�
′
�
�
′
=
2
�
′
�
′{\displaystyle i\mathbf {ds} =2e\mathbf {v} ,i^{\prime }\mathbf {ds} ^{\prime }=2e^{\prime }\mathbf {v} ^{\prime }};

so the mutual energy of two current-elements is

�
�
′
�
3
(
�
.
�
�
′
)
.
(
�
.
�
�
)
{\displaystyle {\frac {ii^{\prime }}{r^{3}}}(\mathbf {r.ds^{\prime }} ).(\mathbf {r.ds} )}.

The mutual energy of ids with all the other currents is therefore

�
(
�
�
.
�
)
{\displaystyle i(\mathbf {ds.a} )},

where a denotes a vector-potential

∫
�
′
�
′
(
�
.
�
�
′
)
.
�
�
3
{\displaystyle \int _{s^{\prime }}i^{\prime }{\frac {(\mathbf {r.ds^{\prime }} )\mathbf {.r} }{r^{3}}}}.

By reasoning similar to Neumann's, it may be shown that the electromotive force induced in ds by any alteration in the rest of the field is

−
(
�
�
.
�
˙
)
{\displaystyle -(\mathbf {ds.{\dot {a}}} )}.

and thus a complete theory of induced currents may be constructed.

The necessity for induced currents may be inferred by general reasoning from the first principles of Weber's theory. When a circuit's moves in the field due to currents, the velocity of the vitreous charges in s is, owing to the motion of s, not equal and opposite to that of the resinous charges: this gives rise to a difference in the forces acting on the vitreous and resinous charges in s; and hence the charges of opposite sign separate from each other and move in opposite directions.

The assumption that positive and negative charges move with equal and opposite velocities relative to the matter of ​the conductor is one to which, for various reasons which will appear later, objection may be taken; but it is an integral part of Weber's theory, and cannot be excised from it. In fact, if this condition were not satisfied, and if the law of force were Weber's, electric currents would exert forces on electrostatic charges at rest[10]; as may be seen by the following example. Let a current flow in a closed circuit formed by arcs of two concentric circles and the portions of the radii connecting their extremities; then, if Weber's law were true, and if only one kind of electricity were in motion, the current would evidently exert an electrostatic force on a charge placed at the centre of the circles. It has been shown,[11] indeed, that the assumption of opposite electricities moving with equal and opposite velocities in a circuit is almost inevitable in any theory of the type of Weber's, so long as the mutual action of two charges is assumed to depend only on their relative (as opposed to their absolute) motion.

The law of Weber is not the only one of its kind; an alternative to it was suggested by Bernhard Riemann (b.1826, d. 1866), in a course of lectures which were delivered[12] at Göttingen in 1861, and which were published after his death by K. Hattendorff, Riemann proposed as the electrokinetic energy of two electrons e(x, y, z) and e′(x′, y′, z′) the expression

−
1
2
�
�
′
�
{
(
�
˙
−
�
˙
′
)
2
+
(
�
˙
−
�
˙
′
)
2
+
(
�
˙
−
�
˙
′
)
2
}
{\displaystyle -{\frac {1}{2}}{\frac {ee^{\prime }}{r}}\{({\dot {x}}-{\dot {x}}^{\prime })^{2}+({\dot {y}}-{\dot {y}}^{\prime })^{2}+({\dot {z}}-{\dot {z}}^{\prime })^{2}\}};

this differs from the corresponding expression given by Weber only in that the relative velocity of the two electrons is substituted in place of the component of this velocity along the radius vector. Eventually, as will be seen later, the laws ​of Riemann and Weber were both abandoned in favour of a third alternative.

At the time, however, Weber's discovery was felt to be a great advance; and indeed it had, perhaps, the greatest share in awakening mathematical physicists to a sense of the possibilities latent in the theory of electricity. Beyond this, its influence was felt in general dynamics; for Weber's electrokinetic energy, which resembled kinetic energy in some respects and potential energy in others, could not be precisely classified under either head; and its introduction, by helping to break down the distinction which had hitherto subsisted between the two parts of the kinetic potential, prepared the way for the modern transformation-theory of dynamics.[13]

Another subject whose development was stimulated by the work of Weber was the theory of gravitation. That gravitation is propagated by the action of a medium, and consequently is a process requiring time for its accomplishment, had been an article of faith with many generations of physicists. Indeed, the dependence of the force on the distance between the attracting bodies seemed to suggest this idea; for a propagation which is truly instantaneous would, perhaps, be more naturally conceived to be effected by some kind of rigid connexion between the bodies, which would be more likely to give a force independent of the mutual distance.

It is obvious that, if the simple law of Newton is abandoned, there is a wide field of rival hypotheses from which to choose its successor, The first notable attempt to discuss the question was made by Laplace.[14] Laplace supposed gravity to be produced by the impulsion on the attracted body of a "gravific fluid," which flows with a definite velocity toward the centre of attraction——say, the sun. If the attracted body or planet is in motion, the velocity of the fluid relative to it will be compounded of the absolute velocity of the fluid and the reversed velocity of the planet, and the force of gravity will ​act in the direction thus determined, its magnitude being unaltered by the planet's motion. This amounts to supposing that gravity is subject to an aberrational effect similar to that observed in the case of light. It is easily seen that the modification thus introduced into Newton's law may be represented by an additional perturbing force, directed along the tangent to the orbit in the opposite sense to the motion, and proportional to the planet's velocity and to the inverse square of the distance from the sun. By considering the influence of this force on the secular equation of the moon's motion, Laplace found that the velocity of the gravific fluid must be at least a hundred million times greater than that of light.

The assumptions made by Laplace are evidently in the highest degree questionable; but the generation immediately succeeding, overawed by his fame, seems to have found no way of improving on them. Under the influence of Weber's ideas, however, astronomers began to think of modifying Newton's law by adding a term involving the velocities of the bodies. Tisserand[15] in 1872 discussed the motion of the planets round the sun on the supposition that the law of gravitation is the same as Weber's law of electrodynamic action, so that the force is

�
�
�
�
2
{
1
−
1
ℎ
2
(
�
�
�
�
)
2
+
1
ℎ
2
�
�
2
�
�
�
2
}
{\displaystyle {\frac {fmu}{r^{2}}}\left\{1-{\frac {1}{h^{2}}}\left({\frac {dr}{dt}}\right)^{2}+{\frac {1}{h^{2}}}r{\frac {d^{2}r}{dt^{2}}}\right\}},

where f denotes the constant of gravitation, m the mass of the planet, μ the mass of the sun, r the distance of the planet from the sun, and h the velocity of propagation of gravitation. The equations of motion may be rigorously integrated by the aid of elliptic functions[16]; but the simplest procedure is

�
=
�
�
�
�
2
+
�
1
{\displaystyle F={\frac {fmu}{r^{2}}}+F_{1}},

​and, regarding F1 as a perturbing function, to find the variation of the constants of elliptic motion. Tisserand showed that the perturbations of all the elements are zero or periodic, and quite insensible, except that of the longitude of perihelion, which has a secular part. If h be assumed equal to the velocity of light, the effect would be to rotate the major axis of the orbit of Mercury in the direct sense 14" in a century.
Now, as it happened, a discordance between theory and observation was known to exist in regard to the motion of Mercury's perihelion; for Le Verrier had found that the attraction of the planets might be expected to turn the perihelion 527" in the direct sense in a century, whereas the motion actually observed was greater than this by 38". It is evident, however, that only 
3
8
 of the excess is explained by Tisserand's adoption of Weber's law; and it seemed therefore that this suggestion would prove as unprofitable as Le Verrier's own hypothesis of an intra-mercurial planet. But it was found later[17] that 
3
4
 of the excess could be explained by substituting Riemann's electrodynamic law for Weber's, and that a combination of the laws of Riemann and Weber would give exactly the amount desired.[18]

After the publication of his memoir on the law of force between electrons, Weber turned his attention to the question of diamagnetism, and developed Faraday's idea regarding the explanation of diamagnetic phenomena by the effects of electric currents induced in the diamagnetic bodies.[19] Weber remarked that if, with Ampère, we assume the existence of molecular circuits in which there is no ohmic resistance, so that currents can flow without dissipation of energy, it is quite natural to suppose that currents would be induced in these molecular ​Middle of the Nineteenth Century. 235 circuits if they were situated in a varying magnetic field; and he pointed out that such induced molecular currents would confer upon the substance the properties characteristic of diamagnetism.

The difficulty with this hypothesis is to avoid explaining too much; for, if it be accepted, the inference seems to be that all bodies, without exception, should be diamagnetic. Weber escaped from this conclusion by supposing that in iron and other magnetic substances there exist permanent molecular currents, which do not owe their origin to induction, and which, under the influence of the impressed magnetic force, set themselves in definite orientations. Since a magnetic field tends to give such a direction to a pre-existing current that its course becomes opposed to that of the current which would be induced by the increase of the magnetic force, it follows that a substance stored with such pre-existing currents would display the phenomena of paramagnetism: The bodies ordinarily called paramagnetic are, according to this hypothesis, those bodies in which the paramagnetism is strong enough to mask the diamagnetism.

The radical distinction which Weber postulated between the natures of paramagnetism and diamagnetism accords with many facts which have been discovered subsequently. Thus in 1895 P. Curie showed that the magnetic susceptibility per gramme-molecule is connected with the temperature by laws which are different for paramagnetic and diamagnetic bodies. For the former it varies in inverse proportion to the absolute temperature, whereas for diamagnetic bodies it is independent of the temperature.

The conclusions which followed from the work of Faraday and Weber were adverse to the hypothesis of magnetic fluids; for according to that hypothesis the induced polarity would be in the same direction whether due to a change of orientation of pre-existing molecular magnets, or to a fresh separation of magnetic fluids in the molecules.[20] "Through the discovery of ​diamagnetism," wrote Weber[21] in 1852, "the hypothesis of electric molecular currents in the interior of bodies is corroborated, and the hypothesis of magnetic fluids in the interior of bodies is refuted." The latter hypothesis is, moreover, unable to account for the phenomena shown by bodies which are strongly magnetic, like iron: for it is found that when the magnetizing force is gradually increased to a very large value, the magnetization induced in such bodies does not increase in proportion, but tends to a saturation value This effect cannot be explained on the assumptions of Poisson, but is easily deducible from those of Weber; for, according to Weber's theory, the magnetizing force merely orients existing magnets, and when it has attained such a value that all of them are oriented in the same direction, there is nothing further to be done.

Weber's theory in its original form is, however, open to some objection. If the elementary magnets are supposed to be free to orient themselves without encountering any resistance, it is evident that a very small magnetizing force would suffice to turn them all parallel to each other, and thus would produce immediately the greatest possible intensity of induced magnetism. To overcome this difficulty, Weber assumed that every displacement of a molecular circuit is resisted by a couple, which tends to restore the circuit to its original orientation. This assumption fails, however, to account for the fact that iron which has been placed in a strong magnetic field does not return to its original condition when it is removed from the field, but retains a certain amount of residual magnetization.

Another alternative was to assume a frictional resistance to the rotation of the magnetic molecules; but if such a resistance existed, it could be overcome only by a finite magnetizing force; and this inference is inconsistent with the observation that some degree of magnetization is induced by every force, however feeble.

The hypothesis which has ultimately gained acceptance is that the orientation is resisted by couples which arise from the ​mutual action of the molecular magnets themselves. In the unmagnetized condition the molecules "arrange themselves so as to satisfy their mutual attraction by the shortest path, and thus form a complete closed circuit of attraction," as D. E. Hughes wrote[22] in 1883; when an external magnetizing force is applied, these small circuits are broken up; and at any stage of the process a molecular magnet is in equilibrium under the joint influence of the external force and the forces due to the other molecules.

This hypothesis was suggested by Maxwell,[23] and has been since developed by J. A. Ewing:[24] its consequences may be illustrated by the following simple examples[25]:—

Consider two magnetic molecules, each of magnetic moment m, whose centres are fixed at a distance c apart. When undisturbed, they dispose themselves in the position of stable equilibrium, in which they point in the same direction along the line c. Now let an increasing magnetic force H be made to act on them in a direction at right angles to the line c. The magnets tum towards the direction of H; and when H attains the value 3m/c3, they become perpendicular to the line c, after which they remain in this position, when H is increased further. Thus they display the phenomena of induction initially proportional to the magnetizing force, and of saturation. If the magnetizing force H be supposed to act parallel to the line c, in the direction in which the axes originally pointed, the magnets will remain at rest. But if H acts in the opposite direction, the equilibrium will be stable only so long as H is less than mics; when H increases beyond this limit, the equilibrium becomes unstable, and the magnets turn over so as to point in the direction of H; when H is gradually decreased to zero, they remain in their new positions, thus illustrating the phenomenon of residual magnetism. ​By taking a large number of such pairs of magnetic molecules, originally oriented in all directions, and at such distances that the pairs do not sensibly influence each other, we may construct a model whose behaviour under the influence of an external magnetic field will closely resemble the actual behaviour of ferromagnetic bodies.

In order that the magnets in the model may come to rest in their new positions after reversal, it will be necessary to suppose that they experience some kind of dissipative force which damps the oscillations; to this would correspond in actual magnetic substances the electric currents which would be set up in the neighbouring mass when the molecular magnets are suddenly reversed; in either case, the sudden reversals are attended by a transformation of magnetic energy into heat.

The transformation of energy from one form to another is a subject which was first treated in a general fashion shortly before the middle of the nineteenth century. It had long been known that the energy of motion and the energy of position of a dynamical system are convertible into each other, and that the amount of their sum remains invariable when the system is self-contained. This principle of conservation of dynamical energy had been extended to optics by Fresnel, who had assumed[26] that the energy brought to an interface by incident light is equal to the energy carried away from the interface by the reflected and refracted beams. A similar conception was involved in Roget's and Faraday's defence[27] of the chemical theory of the voltaic cell; they argued that the work done by the current in the outer circuit must be provided at the expense of the chemical energy stored in the cell, and showed that the quantity of electricity sent round the circuit is proportional to the quantity of chemicals consumed, while its tension is proportional to the strength of the chemical affinities concerned in the reaction. This theory was extended ​and completed by James Prescott Joule, of Manchester, in 1841. Joule, who believed[28] that heat is producible from mechanical work and convertible into it, measured[29] the amount of heat evolved in unit time in a metallic wire, through which a current of known strength was passed; he found the amount to be proportional to the resistance of the wire multiplied by the square of the current-strength; or (as follows from Ohm's law) to the current-strength multiplied by the difference of electric tensions at the extremities of the wire.

The quantity of energy yielded ap as heat in the outer circuit being thus known, it became possible to consider the transference of energy in the circuit as a whole. "When," wrote Joule, "any voltaic arrangement, whether simple or compound, passes a current of electricity through any substance, whether an electrolyte or not, the total voltaic heat which is generated in any time is proportional to the number of atoms which are electrolyzed in each cell of the circuit, multiplied by the virtual intensity of the battery: if a decomposing cell be in the circuit, the virtual intensity of the battery is reduced in proportion to its resistance to electrolyzation." In the same year he[30] enhanced the significance of this by showing that the quantities of heat which are evolved by the combustion of the equivalents of bodies are proportional to the intensities of their affinities for oxygen, as measured by the electromotive force of a battery required to decompose the oxide electrolytically.

The theory of Roget and Faraday, thus perfected by Joule, enables us to trace quantitatively the transformations of energy in the voltaic cell and circuit. The primary source of energy is the chemical reaction: in a Daniell cell, Zn|Zn SO4|Cu SO4|Cu, for instance, it is the substitution of zinc for copper as the partner of the sulphion. The strength of the chemical affinities concerned is in this case measured by the difference of the heats of formation of zinc sulphate and copper sulphate; and it is ​this which determines the electromotive force of the cell.[31] The amount of energy which is changed from the chemical to the electrical form in a given interval of time is measured by the product of the strength of the chemical affinity into the quantity of chemicals decomposed in that time, or (what is the same thing) by the product of the electromotive force of the cell into the quantity of electricity which is circulated. This energy may be either dissipated as heat in conformity to Joule's law, or otherwise utilized in the outer circuit.

The importance of these principles was emphasized by Hermann von Helmholtz (b. 1821, d. 1894), in a memoir which was published in 1847, and which will be more fully noticed presently, and by W. Thomson (Lord Kelvin) in 1851[32]; the equations have subsequently received only one important modification, which is due to Helmholtz.[33] Helmholtz pointed out that the electrical energy furnished by a voltaic cell need not be derived exclusively from the energy of the chemical reactions: for the cell may also operate by abstracting heat-energy from neighbouring bodies, and converting this into electrical energy. The extent to which this takes place is determined by a law which was discovered in 1855 by Thomson.[34] Thomson showed that if E denotes the "available energy," i.e., possible output of mechanical work, of a system maintained at the absolute temperature T, then a fraction

�
�
�
�
�
�
{\displaystyle {\frac {T}{E}}{\frac {dE}{dT}}}

of this work is obtained, not at the expense of the thermal or ​chemical energy of the system itself, but at the expense of the thermal energy of neighbouring bodies. Now in the case of the voltaic cell, the principle of Roget, Faraday, and Joule is expressed by the equation

�
=
�{\displaystyle E=\lambda },

where E denotes the available or electrical energy, which is measured by the electromotive force of the cell, and where λ denotes the heat of the chemical reaction which supplies this energy. In accordance with Thomson's principle, we must replace this equation by

�
=
�
+
�
�
�
�
�
{\displaystyle E=\lambda +T{\frac {dE}{dT}}},

which is the correct relation between the electromotive force of a cell and the energy of the chemical reactions which occur in it. In general the term λ is much larger than the term TdE/dT; but in certain classes of cells—e.g., concentration-cells—λ is zero; in which case the whole of the electrical energy is procured at the expense of the thermal energy of the cells' surroundings.

Helmholtz's memoir of 1847, to which reference has already been made, bore the title, "On the Conservation of Force." It was originally read to the Physical Society of Berlin[35]; but though the younger physicists of the Society received it with enthusiasm, the prejudices of the older generation prevented its acceptance for the Annalen der Physik; and it was eventually published as a separate treatise.[36]

In this memoir it was asserted[37] that the conservation of ​energy is a universal principle of nature: that the kinetic and potential energy of dynamical systems may be converted into heat according to definite quantitative laws, as taught by Rumford, Joule, and Robert Mayer[38]; and that any of these forms of energy may be converted into the chemical, electrostatic, voltaic, and magnetic forces. The latter Helmholtz examined systematically.

Consider first the energy of an electrostatic field. It will be convenient to suppose that the system has been formed by continually bringing from a very great distance infinitesimal quantities of electricity, proportional to the quantities already present at the various points of the system; so that the charge is always distributed proportionally to the final distribution. Let e typify the final charge at any point of space, and V the final potential at this point. Then at any stage of the process the charge and potential at this point will have the values λc and λV, where λ denotes a proper fraction. At this stage let charges edλ be brought from a great distance and added to the charges λe. The work required for this is

Σ
�
�
�
.
�
�
{\displaystyle \Sigma ed\lambda .\lambda V},

so the total work required in order to bring the system from infinite dispersion to its final state is

Σ
�
�
.
∫
0
1
�
�
�{\displaystyle \Sigma eV.\int _{0}^{1}\lambda d\lambda }, or 
1
2
Σ
�
�
{\displaystyle {\tfrac {1}{2}}\Sigma eV}.

By reasoning similar to that used in the case of electrostatic distributions, it may be shown that the energy of a magnetic field, which is due to permanent magnets and which also contains bodies susceptible to magnetic induction, is

1
2
∭
�
0
�
 
�
�
 
�
�
 
�
�
{\displaystyle {\tfrac {1}{2}}\iiint \rho _{0}\phi \ dx\ dy\ dz},

where ρ0 denotes the density of Poisson's equivalent magnetiza​tion, for the permanent magnets only, and φ denotes the magnetic potential.[39]

Helmholtz, moreover, applied the principle of energy to systems containing electric currents. For instance, when a magnet is moved in the vicinity of a current, the energy taken from the battery may be equated to the sum of that expended as Joulian heat, and that communicated to the magnet by the electromagnetic force: and this equation shows that the current is not proportional to the electromotive force of the battery, i.e. it reveals the existence of Faraday's magneto-electric induction, As, however, Helmholtz was at the time unacquainted with the conception of the electrokinetic energy stored in connexion with a current, his equations were for the most part defective. But in the case of the mutual action of a current and a permanent magnet, he obtained the correct result that the time-integral of the induced electromotive force in the circuit is equal to the increase which takes place in the potential of the magnet towards a current of a certain strength in the circuit.

The correct theory of the energy of magnetic and electromagnetic fields is due mainly to W. Thomson (Lord Kelvin). Thomson's researches on this subject commenced with one or two short investigations regarding the ponderomotive forces which act on temporary magnets. In 1847 he discussed[40] the case of a small iron sphere placed in a magnetic field, showing that it is acted on by a ponderomotive force represented by - grad cR2, where c denotes a constant, and R denotes the magnetic force of the field; such a sphere must evidently tend to move towards the places where R2 is greatest. The same analysis may be applied to explain why diamagnetic bodies tend to move, as in Faraday's experiments, from the stronger to the weaker parts of the field.

​Two years later Thomson presented to the Royal Society a memoir[41] in which the results of Poisson's theory of magnetism were derived from experimental data, without making use of the hypothesis of magnetic fluids; and this was followed in 1850 by a second memoir,[42] in which Thomson drew attention to the fact previously noticed by Poisson,[43] that the magnetic intensity at a point within a magnetized body depends on the shape of the small cavity in which the exploring magnet is placed. Thomson distinguished two vectors;[44] one of these, by later writers generally denoted by B, represents the magnetic intensity at a point situated in a small crevice in the magnetized body, when the faces of the crevice are at right angles to the direction of magnetization; the vector B is always circuital. The other vector, generally denoted by H, represents the magnetic intensity in a narrow tubular cavity tangential to the direction of magnetization; it is an irrotational vector, The magnetic potential tends at any point to a limit which is independent of the shape of the cavity in which the point is situated; and the space-gradient of this limit is identical with H. Thomson called B the "magnetic force according to the electro-magnetic definition," and H the "magnetic force according to the polar definition"; but the names magnetic induction and magnetic force, proposed by Maxwell, have been generally used by later writers.

It may be remarked that the vector to which Faraday applied the term "magnetic force," and which he represented by lines of force, is not H, but B; for the number of unit lines of force passing through any gap must depend only on the gap, and not on the particular diaphragm filling up the gap, across which the flux is estimated; and this can be the case only if the vector which is represented by the lines of force is a circuital vector.

​Thomson introduced a number of new terms into magnetic science—as indeed he did into every science in which he was interested. The ratio of the measure of the induced magnetization Ii, in a temporary magnet, to the magnetizing force H, he named the susceptibility; it is positive for paramagnetic and negative for diamagnetic bodies, and is connected with Poisson's constant kp[45] by the relation

�
=
3
�
�
�
�
1
−
�
�
{\displaystyle \kappa ={\frac {3}{r\pi }}{\frac {k_{p}}{1-k_{p}}}},

where κ denotes the susceptibility. By an easy extension of Poisson's analysis it is seen that the magnetic induction and magnetic force are connected by the equation

�
=
�
+
4
�
�
{\displaystyle \mathbf {B} =\mathbf {H} +4\pi \mathbf {I} },

where I denotes the total intensity of magnetization: so if I0, denote the permanent magnetization, we have

�
=
�
+
4
�
�
�
+
4
�
�
0
=
�
�
+
4
�
�
0
{\displaystyle {\begin{matrix}\mathbf {B} &=&\mathbf {H} +4\pi \mathbf {I_{i}} +4\pi \mathbf {I} _{0}\\&=&\mu \mathbf {H} +4\pi \mathbf {I} _{0}\end{matrix}}}

where μ denotes (1 + 4πκ): μ was called by Thomson the permeability.

In 1851 Thomson extended his magnetic theory so as to include magnecrystallic phenomena. The mathematical foundations of the theory of magnecrystallic action had been laid by anticipation, long before the experimental discovery of the phenomenon, in a memoir read by Poisson to the Academy in February, 1824. Poisson, as will be remembered, had supposed temporary magnetism to be due to "magnetic fields," movable within the infinitely small "magnetic elements" of which he assumed magnetizable matter to be constituted. He had not overlooked the possibility that in crystals these magnetic elements might be non-spherical (e.g. ellipsoidal), and symmetrically arranged; and had remarked that a portion of such a crystal, when placed in a magnetic field, would act in a manner depending on its orientation. The relations connecting ​the induced magnetization I with the magnetizing force H he had given in a form equivalent to

{
�
�
=
�
�
�
+
�
′
�
�
+
�
′
′
�
�
,
�
�
=
�
′
′
�
�
+
�
�
�
+
�
′
�
�
,
�
�
=
�
′
�
�
+
�
′
′
�
�
+
�
�
�
.
{\displaystyle {\begin{cases}I_{x}=aH_{x}+b^{\prime }H_{y}+c^{\prime \prime }H_{z},\\I_{y}=a^{\prime \prime }H_{x}+bH_{y}+c^{\prime }H_{z},\\I_{z}=a^{\prime }H_{x}+b^{\prime \prime }H_{y}+cH_{z}.\end{cases}}}

Thomson now[46] showed that the nine coefficients a, b′, c′′ …, introduced by Poisson, are not independent of each other. kor a sphere composed of the magnecrystalline substance, iſ placed in a uniform field of force, would be acted on by a couple: and the work done by this couple when the sphere, supposed of unit volume, performs a complete revolution round the axis of x may be easily shown to be 
�
�
(
1
−
�
�
2
/
�
2
)
(
−
�
′
′
+
�
′
)
{\displaystyle \textstyle \pi H(1-H_{x}^{2}/\mathbf {H} ^{2})(-b^{\prime \prime }+c^{\prime })}. But this work must be zero, since the system is restored to its primitive condition; and hence b′′ and c′ must be equal. Similarly c′′ =a′, and a′′ = b′. By change of axes three more coefficients may be removed, so that the equations may be brought to the form

�
�
=
�
1
�
�
,
�
�
=
�
2
�
�
,
�
�
=
�
3
�
�
{\displaystyle I_{x}=\kappa _{1}H_{x},I_{y}=\kappa _{2}H_{y},I_{z}=\kappa _{3}H_{z}},

where κ1, κ2, κ3 may be called the principal magnetic susceptibilities.

In the same year (1851) Thomson investigated the energy which, as was evident from Faraday's work on self-induction, must be stored in connexion with every electric current. He showed that, in his own words,[47] "the value of a current in a closed conductor, left without electromotive force, is the quantity of work that would be got by letting all the infinitely small currents into which it may be divided along the lines of motion of the electricity come together from an infinite distance, and make it up Each of these 'infinitely small currents' is of course in a circuit which is generally of finite length; it is the section of each partial conductor and the strength of the current in it that must be infinitely small."

​Discussing next the mutual energy due to the approach of a permanent magnet and a circuit carrying a current, he arrived at the remarkable conclusion that in this case there is no electrokinetic energy which depends on the mutual action; the energy is simply the sum of that due to the permanent magnets and that due to the currents. If a permanent magnet is caused to approach a circuit carrying a current, the electromotive force acting in the circuit is thereby temporarily increased; the amount of energy dissipated as Joulian heat, and the speed of the chemical reactions in the cells, are temporarily increased also. But the increase in the Joulian heat is exactly equal to the increase in the energy derived from consumption of chemicals, together with the mechanical work done on the magnet by the operator who moves it; so that the balance of energy is perfect, and none needs to be added to or taken from the electrokinetic form. It will now be evident why it was that Helmholtz escaped in this case the errors into which he was led in other cases by his neglect of electrokinetic energy; for in this case there was no electrokinetic energy to neglect.

Two years later, in 1853, Thomson[48] gave a new form to the expression for the energy of a system of permanent and temporary magnets.

We have seen that the energy of such a system is represented by

1
2
∭
�
0
�
�
�
 
�
�
 
�
�
{\displaystyle {\tfrac {1}{2}}\iiint \rho _{0}\phi dx\ dy\ dz},

where ρe denotes the density of Poisson's equivalent magnetization for the permanent magnets, and φ denotes the magnetic potential, and where the integration may be extended over the whole of space. Substituting for ρ0 its value - div I0,[49] the expression may be written in the form

−
1
2
∭
�
d
i
v
 
�
0
 
�
�
 
�
�
 
�
�
{\displaystyle -{\tfrac {1}{2}}\iiint \phi \mathrm {div} \ \mathbf {I} _{0}\ dx\ dy\ dz};

​or, integrating by parts,
−
1
2
∭
(
�
0
.
g
r
a
d
 
�
)
 
�
�
 
�
�
 
�
�
{\displaystyle -{\tfrac {1}{2}}\iiint (\mathbf {I} _{0}.\mathrm {grad} \ \phi )\ dx\ dy\ dz}, or 
−
1
2
∭
(
�
.
�
0
)
 
�
�
 
�
�
 
�
�
{\displaystyle -{\tfrac {1}{2}}\iiint (\mathbf {H.} \mathbf {I} _{0})\ dx\ dy\ dz}.

Since B = μH + 4πI0, this expression may be written in the form

−
1
8
�
∭
(
�
.
�
)
 
�
�
 
�
�
 
�
�
+
1
8
�
∭
�
�
2
 
�
�
 
�
�
 
�
�
{\displaystyle -{\frac {1}{8\pi }}\iiint (\mathbf {H.B} )\ dx\ dy\ dz+{\frac {1}{8\pi }}\iiint \mu \mathbf {H} ^{2}\ dx\ dy\ dz};

but the former of these integrals is equivalent to

∭
(
�
.
g
r
a
d
 
�
)
 
�
�
 
�
�
 
�
�
{\displaystyle \iiint (\mathbf {B.} \mathrm {grad} \ \phi )\ dx\ dy\ dz}, or 
−
∭
�
d
i
v
 
�
 
�
�
 
�
�
 
�
�
{\displaystyle -\iiint \phi \mathrm {div} \ \mathbf {B} \ dx\ dy\ dz},

which vanishes, since B is a circuital vector. The energy of the field, therefore, reduces to

1
8
�
∭
�
�
2
 
�
�
 
�
�
 
�
�
{\displaystyle {\frac {1}{8\pi }}\iiint \mu \mathbf {H} ^{2}\ dx\ dy\ dz},

integrated over all space; which is equivalent to Thomson's form.[50]

In the same memoir Thomson returned to the question of the energy which is possessed by a circuit in virtue of an electric current circulating in it. As he remarked, the energy may be determined by calculating the amount of work which must be done in and on the circuit in order to double the circuit on itself while the current is sustained in it with constant strength; for Faraday's experiments show that a circuit doubled on itself has no stored energy. Thomson found that the amount of work required may be expressed in the form 
1
2
Li2, where i denotes the current strength, and L, which is called the coefficient of self-induction, depends only on the form of the circuit.

It may be noticed that in the doubling process the inherent ​electrodynamic energy is being given up, and yet the operator is doing positive work. The explanation of this apparent paradox is that the energy derived from both these sources is being used to save the energy which would otherwise be furnished by the battery, and which is expended in Joulian heat.

Thomson next proceeded[51] to show that the energy which is stored in connexion with a circuit in which a current is flowing may be expressed as a volume-integral extended over the whole of space, similar to the integral by which he had already represented the energy of a system of permanent and temporary magnets. The theorem, as originally stated by its author, applied only to the case of a single circuit; but it may be established for a system formed by any number of circuits in the following way:—

If Ns denote the number of unit tubes of magnetic induction which are linked with the sth circuit, in which a current is is flowing, the electrokinetic energy of the system is 
1
2
∑
�
�
�
�
�
{\displaystyle \textstyle {\frac {1}{2}}\sum _{s}N_{s}i_{s}}; which may be written 
1
2
∑
�
�
�
{\displaystyle \textstyle {\frac {1}{2}}\sum _{r}I_{r}}, where Ir, denotes the total current flowing through the gap formed by the rth path unit tube of magnetic induction. But if H denote the (vector) magnetic force, and H its numerical magnitude, it is known that (1/4π)∫ Hds, integrated along a closed line of magnetic induction, measures the total current flowing through the gap formed by the line. The energy is therefore 
1
8
�
∑
∫
�
�
�
{\displaystyle \textstyle {\frac {1}{8\pi }}\sum \int Hds}, the summation being extended over all the unit tubes of magnetic induction, and the integration being taken along them. But if dS denote the cross-section of one of these tubes, we have BdS = 1, where B denotes the numerical magnitude of the magnetic induction B: so the energy is 
1
8
�
∑
�
�
�
∫
�
�
�
{\displaystyle \textstyle {\frac {1}{8\pi }}\sum BdS\int Hds}; and as the tubes fill all space, we may replace 
∑
�
�
∫
�
�
{\displaystyle \textstyle \sum dS\int ds} by 
∭
 
�
�
 
�
�
 
�
�
{\displaystyle \textstyle \iiint \ dx\ dy\ dz}. Thus the energy takes the form 
1
8
�
∭
�
�
 
�
�
 
�
�
 
�
�
{\displaystyle \textstyle {\frac {1}{8\pi }}\iiint BH\ dx\ dy\ dz}, where the integration is extended over the whole of space; and since in the present case B = μH, the energy may also be represented by 
1
8
�
∭
�
�
2
 
�
�
 
�
�
 
�
�
{\displaystyle \textstyle {\frac {1}{8\pi }}\iiint \mu H^{2}\ dx\ dy\ dz}.

​But this is identical with the form which was obtained for a field due to permanent and temporary magnets. It thus appears that in all cases the stored energy of a system of electric currents and permanent and temporary magnets is

1
8
�
∭
�
�
2
 
�
�
 
�
�
 
�
�
{\displaystyle {\frac {1}{8\pi }}\iiint \mu H^{2}\ dx\ dy\ dz},

where the integration is extended over all space.

It must, however, be remembered that this represents only what in thermodynamics is called the "available energy"; and it must further be remembered that part even of this available energy may not be convertible into mechanical work within the limitations of the system: e.g., the electrokinetic energy of a current flowing in a single closed perfectly conducting circuit cannot be converted into any other for so long as the circuit is absolutely rigid. All that we can say is that the changes in this stored electrokinetic energy correspond to the work furnished by the system in any change.

The above form suggests that the energy may not be localized in the substance of the circuits and magnets, but may be distributed over the whole of space, an amount (μH2/8π) of energy being contained in each unit volume. This conception was afterwards adopted by Maxwell, in whose theory it is of fundamental importance.

While Thomson was investigating the energy stored in connexion with electric currents, the equations of flow of the currents were being generalized by Gustav Kirchhoff (b. 1824, d. 1887). In 1848 Kirchhoff[52] extended Ohm's theory of linear conduction to the case of conduction in three dimensions; this could be done without much difficulty by making use of the analogy with the flow of heat, which had proved so useful to Ohm. In Kirchhoff's memoir a system is supposed to be formed of three-dimensional conductors, through which steady currents are flowing. At any point let V denote the "tension" or "electroscopic force"—a quantity the significance of which ​in electrostatics was not yet correctly known. Then, within the substance of any homogeneous conductor, the function V must satisfy Laplace's equation ∇2V = 0; while at the air-surface of each conductor, the derivate of V taken along the normal must vanish. At the interface between two conductors formed of different materials, the function V has a discontinuity, which is measured by the value of Volta's contact force for the two conductors; and, moreover, the condition that the current shall be continuous across such an interface requires that k∂V/∂N shall be continuous, where k denotes the ohmic specific conductivity of the conductor, and ∂/∂N denotes differentiation along the normal to the interface. The equations which have now been mentioned suffice to determine the flow of electricity in the system.

Kirchhoff also showed that the currents distribute themselves in the conductors in such a way as to generate the least possible amount of Joulian heat; as is easily seen, since the quantity of Joulian heat generated in unit time is

∭
�
{
(
∂
�
∂
�
)
2
+
(
∂
�
∂
�
)
2
+
(
∂
�
∂
�
)
2
}
 
�
�
 
�
�
 
�
�
{\displaystyle \iiint k\left\{\left({\frac {\partial V}{\partial x}}\right)^{2}+\left({\frac {\partial V}{\partial y}}\right)^{2}+\left({\frac {\partial V}{\partial z}}\right)^{2}\right\}\ dx\ dy\ dz},

where k, as before, denotes the specific conductivity, and this integral has a stationary value when V satisfies the equation

∂
∂
�
(
�
∂
�
∂
�
)
+
∂
∂
�
(
�
∂
�
∂
�
)
+
∂
∂
�
(
�
∂
�
∂
�
)
{\displaystyle {\frac {\partial }{\partial x}}\left(k{\frac {\partial V}{\partial x}}\right)+{\frac {\partial }{\partial y}}\left(k{\frac {\partial V}{\partial y}}\right)+{\frac {\partial }{\partial z}}\left(k{\frac {\partial V}{\partial z}}\right)}.

Kirchhoff next applied himself to establish harmony between electrostatical conceptions and the theory of Ohm. That theory had now been before the world for twenty years, and had been verified by numerous experimental researches; in particular, a careful investigation was made at this time (1848) by Rudolph Kohlrausch (b. 1809, d. 1858), who showed[53] that the difference of the electric "tensions" at the extremities of a voltaic cell, measured electrostatically with the circuit open, was for different cells proportional to the electromotive force ​measured by the electrodynamic effects of the cell with the circuit closed; and, further,[54] that when the circuit was closed, the difference of the tensions, measured electrostatically, at any two points of the outer circuit was proportional to the ohmic resistance existing between them. But in spite of all that had been done, it was still uncertain how "tension," or "electroscopic force," or "electromotive force" should be interpreted in the language of theoretical electrostatics; it will be remembered that Ohm himself, perpetuating a confusion which had originated with Volta, had identified electroscopic force with density of electric charge, and had assumed that the electricity in a conductor is at rest when it is distributed uniformly throughout the substance of the conductor.

The uncertainty was finally removed in 1849 by Kirchhoff,[55] who identified Ohm's electroscopic force with the electrostatic potential. That this identification is correct may be seen by comparing the different expressions which have been obtained for electric energy: Helmholtz's expression[56] shows that the energy of a unit charge at any place is proportional to the value of the electrostatic potential at that place; while Joule's result[57] shows that the energy liberated by a unit charge in passing from one place in a circuit to another is proportional to the difference of the electric tensions at the two places. It follows that tension and potential are the same thing.

The work of Kirchhoff was followed by several other investigations which belong to the borderland between electrostatics and electrodynamics. One of the first of these was the study of the Leyden jar discharge.

Early in the century Wollaston, in the course of his experiments on the decomposition of water, had observed that when the decomposition is effected by a discharge of static electricity, the hydrogen and oxygen do not appear at separate electrodes; but that at each electrode there is evolved a mixture of the ​gases, as if the current had passed through the water in both directions. After this F. Savary[58] had noticed that the discharge of a Leyden jar magnetizes needles in alternating layers, and had conjectured that "the electric motion during the discharge consists of a series of oscillations." A similar remark was made in connexion with a similar observation by Joseph Henry (b. 1799, d. 1878), of Washington, in 1842.[59]

"The phenomena," he wrote, "require us to admit the existence of a principal discharge in one direction, and then several reflex actions backward and forward, each more feeble than the preceding, until equilibrium is restored." Helmholtz had repeated the same suggestion in his essay on the conservation of energy: and in 1853 W. Thomson[60] verified it, by investigating the mathematical theory of the discharge, as follows:—

Let C denote the capacity of the jar, i.e., the measure of the charge when there is unit difference of potential between the coatings; let R denote the ohmic resistance of the discharging circuit, and L its coefficient of self-induction. Then if at any instant t the charge of the condenser be Q, and the current in the wire be i, we have i = dQ/dt; while Ohm's law, modified by taking self-induction into account, gives the equation

�
�
+
�
�
�
�
�
=
−
�
�
{\displaystyle Ri+L{\frac {di}{dt}}=-{\frac {Q}{C}}}.

Eliminating i, we have

�
�
2
�
�
�
2
+
�
�
�
�
�
+
1
�
�
=
0
{\displaystyle L{\frac {d^{2}Q}{dt^{2}}}+R{\frac {dQ}{dt}}+{\frac {1}{C}}Q=0},

an equation which shows that when R2C < 4L, the subsidence of Q to zero is effected by oscillations of period

2
�
(
1
�
�
−
�
2
4
�
2
)
−
1
2
{\displaystyle 2\pi \left({\frac {1}{LC}}-{\frac {R^{2}}{4L^{2}}}\right)^{-{\tfrac {1}{2}}}}

​This simple result may be regarded as the beginning of the theory of electric oscillations.
Thomson was at this time much engaged in the problems of submarine telegraphy; and thus lie was led to examine the vexed question of the "velocity of electricity" over long insulated wires and cables. Various workers had made experiments on this subject at different times, but with hopelessly discordant results. Their attempts had generally taken the form of measuring the interval of time between the appearance of sparks at two spark-gaps in the same circuit, between which a great length of wire intervened, but which were brought near each other in order that the discharges might be seen together, In one series of experiments, performed by Watson at Shooter's Hill in 1747-8,[61] the circuit was four miles in length, two miles through wire and two miles through the ground; but the discharges appeared to be perfectly simultaneous; whence Watson concluded that the velocity of propagation of electric effects is too great to be measurable.

In 1834 Charles Wheatstone,[62] Professor of Experimental Philosophy in King's College, London, by examining in a revolving mirror sparks formed at the extremities of a circuit, found the velocity of electricity in a copper wire to be about one and a half times the velocity of light. In 1850 H. Fizeau and E. Gounelle,[63] I experimenting with the telegraph lines from Paris to Rouen and to Amiens, obtained a velocity about one-third that of light for the propagation of electricity in an iron wire, and nearly two-thirds that of light for the propagation in a copper wire.

The first step towards explaining these discrepancies was made by Faraday, who[64] early in 1854 showed experimentally that a submarine cable, formed of copper wire covered with ​gutta-percha, "may be assimilated exactly to an immense Leyden battery; the glass of the jars represents the gutta-percha; the internal coating is the surface of the copper wire," while the outer coating corresponds to the sea-water. It follows that in all calculations relating to the propagation of electric disturbances along submarine cables, the electrostatic capacity of the cable must be taken into account.

The theory of signalling by cable originated in a correspondence between Stokes and Thomson in 1854. In the case of long submarine lines, the speed of signalling is so much limited by the electrostatic factor that electro-magnetic induction has no sensible effect; and it was accordingly neglected in the investigation. In view of other applications of the analysis, however, we shall suppose that the cable has a self-induction L per unit length, and that R denotes the ohmic resistance, and C the capacity per unit length, V the electric potential at a distance x from one terminal, and i the current at this place. Ohm's law, as modified for inductance, is expressed by the equation

−
∂
�
∂
�
=
�
∂
�
∂
�
+
�
�
{\displaystyle -{\frac {\partial V}{\partial x}}=L{\frac {\partial i}{\partial t}}+Ri};

moreover, since the rate of accumulation of charge in unit length at x is - ∂i/∂x, and since this increases the potential at the rate - (1/C)∂i/∂x, we have

�
∂
�
∂
�
=
−
∂
�
∂
�
{\displaystyle C{\frac {\partial V}{\partial t}}=-{\frac {\partial i}{\partial x}}}.

Eliminating i between these two equations, we have

1
�
∂
2
�
∂
�
2
=
�
∂
2
�
∂
�
2
+
�
∂
�
∂
�
{\displaystyle {\frac {1}{C}}{\frac {\partial ^{2}V}{\partial x^{2}}}=L{\frac {\partial ^{2}V}{\partial t^{2}}}+R{\frac {\partial V}{\partial t}}},

which is known as the equation of telegraphy.[65]

Thomson, in one of his letters[66] to Stokes in 1854, obtained this equation in the form which applies to Atlantic cables, i.e., with the term in L neglected. In this form it is ​the same as Fourier's equation for the linear propagation of heat: so that the known solutions of Fourier's theory may be used in a new interpretation. If we substitute

�
=
�
2
�
�
−
1
+
�
�
{\displaystyle V=e^{2nt{\sqrt {-1}}+\lambda x}},

we obtain

�
=
±
(
1
+
−
1
)
(
�
�
�
)
1
2
{\displaystyle \lambda =\pm (1+{\sqrt {-1}})(nCR)^{\frac {1}{2}}};

and therefore a typical elementary solution of the equation is

�
=
�
−
(
�
�
�
)
1
2
�
sin
⁡
{
2
�
�
−
(
�
�
�
)
1
2
�
}
{\displaystyle V=e^{-(nCR)^{\frac {1}{2}}x}\sin\{2nt-(nCR)^{\frac {1}{2}}x\}}.

The form of this solution shows that if a regular harmonic variation of potential is applied at one end of a cable, the phase is propagated with a velocity which is proportional to the square root of the frequency of the oscillations: since therefore the different harmonics are propagated with different velocities, it is evident that no definite "velocity of transmission" is to be expected for ordinary signals. If a potential is suddenly applied at one end of the cable, a certain time elapses before the current at the other end attains a definite percentage of its maximum value; but it may easily be shown[67] that this retardation is proportional to the square of the length of the cable, so that the apparent velocity of propagation would be less, the greater the length of cable used.

The case of a telegraph line insulated in the air on poles is different from that of a cable; for here the capacity is small, and it is necessary to take into account the inductance. If in the general equation of telegraphy we write

�
=
�
�
�
−
1
+
�
�
{\displaystyle V=e^{nx{\sqrt {-1}}+\mu t}},

we obtain the equation

�
=
−
�
2
�
±
(
�
2
4
�
2
−
�
2
�
�
)
1
2
{\displaystyle \mu =-{\frac {R}{2L}}\pm \left({\frac {R^{2}}{4L^{2}}}-{\frac {n^{2}}{CL}}\right)^{\frac {1}{2}}};

as the capacity is small, we may replace the quantity under the radical by its second term: and thus we see that a typical elementary solution of the equation is

�
=
�
−
�
�
2
�
sin
⁡
�
{
�
−
(
�
�
)
−
1
2
�
}
{\displaystyle V=e^{-{\frac {Rt}{2L}}}\sin {n\{x-(CL)^{-{\frac {1}{2}}}t\}}};

​this shows that any harmonic disturbance, and therefore any disturbance whatever, is propagated along the wire with velocity (CL)-
1
2
. The difference between propagation in an aerial wire and propagation in an oceanic cable is, as Thomson remarked, similar to the difference between the propagation of an impulsive pressure through a long column of fluid in a tube when the tube is rigid (case of the aerial wire) and when it is elastic, so as to be capable of local distension (case of the cable, the distension corresponding to the effect of capacity): in the former case, as is well known, the impulse is propagated with a definite velocity, namely, the velocity of sound in the fluid.
The work of Thomson on signalling along cables was followed in 1857 by a celebrated investigation[68] of Kirchhoff's, on the propagation of electric disturbance along an aerial wire of circular cross-section.

Kirchhoff assumed that the electric charge is practically all resident on the surface of the wire, and that the current is uniformly distributed over its cross-section; his idea of the current was the same as that of Fechner and Weber, namely, that it consists of equal streams of vitreous and resinous electricity flowing in opposite directions. Denoting the electric potential by V, the charge per unit length of wire by e, the length of the wire by l, and the radius of its cross-section by α, he showed that V is determined approximately by the equation[69]

�
=
2
�
l
o
g
(
�
/
�
)
{\displaystyle V=2e\mathrm {log} (l/\alpha )}.

​The next factor to be considered is the mutual induction of the current-elements in different parts of the wire. Assuming with Weber that the electromotive force induced in an clement ds due to another element ds′ carrying a current i′ is derivable from a vector-potential

�
′
(
�
.
�
�
′
)
.
�
�
3
{\displaystyle i^{\prime }{\frac {(\mathbf {r.ds^{\prime }} )\mathbf {.r} }{r^{3}}}},

Kirchhoff found for the vector-potential due to the entire wire the approximate value

�
=
2
�
log
⁡
(
�
/
�
)
{\displaystyle w=2i\log(l/\alpha )},

where i denotes the strength of the current;[70] the vector-potential being directed parallel to the wire. Ohm's law then gives the equation

�
=
−
�
�
�
2
(
∂
�
∂
�
+
1
�
2
∂
�
∂
�
)
{\displaystyle i=-\pi k\alpha ^{2}\left({\frac {\partial V}{\partial x}}+{\frac {1}{c^{2}}}{\frac {\partial w}{\partial t}}\right)},

where k denotes the specific conductivity of the material of which the wire is composed; and finally the principle of conservation of electricity gives the equation

∂
�
∂
�
=
−
∂
�
∂
�
{\displaystyle {\frac {\partial i}{\partial x}}=-{\frac {\partial e}{\partial t}}}.

Denoting log (l/α) by γ, and eliminating e, i, w from these four equations, we have

∂
2
�
∂
�
2
=
1
�
2
∂
2
�
∂
�
2
+
1
2
�
�
�
�
2
∂
�
∂
�
{\displaystyle {\frac {\partial ^{2}V}{\partial x^{2}}}={\frac {1}{c^{2}}}{\frac {\partial ^{2}V}{\partial t^{2}}}+{\frac {1}{2\gamma \kappa \pi \alpha ^{2}}}{\frac {\partial V}{\partial t}}},

which is, as might have been expected, the equation of telegraphy. When the term in a ∂V/∂t is ignored, as we have seen is in certain cases permissible, the equation becomes

∂
2
�
∂
�
2
=
1
�
2
∂
2
�
∂
�
2
{\displaystyle {\frac {\partial ^{2}V}{\partial x^{2}}}={\frac {1}{c^{2}}}{\frac {\partial ^{2}V}{\partial t^{2}}}},

​which shows that the electric disturbance is propagated along the wire with the velocity c.[71] Kirchhoff's procedure has, in fact, involved the calculation of the capacity and self-induction of the wire, and is thus able to supply the definite values of the quantities which were left undetermined in the general equation of telegraphy.
The velocity c, whose importance was thus demonstrated, has already been noticed in connexion with Weber's law of force; it is a factor of proportionality, which must be introduced when electrodynamic phenomena are described in terms of units which have been defined electrostatically,[72] or conversely when units which have been defined electrodynamically[73] are used in the description of electrostatic phenomena. That the factor which is introduced on such occasions must be of the dimensions (length/time), may be easily seen: for the electrostatic repulsion between electric charges is a quantity of the same kind as the electrodynamic repulsion between two definite lengths of wire, carrying currents which may be specified by the amount of charge which travels past any point in unit time.

Shortly before the publication of Kirchhoff's memoir, the value of c had been determined by Weber and Kohlrausch;[74] their determination rested on a comparison of the measures of the charge of a Leyden jar, as obtained by a method depending on electrostatic attraction, and by a method depending on the ​magnetic effects of the current produced by discharging the jar. The resulting value was nearly

c = 3·1 × 1010 cm./sec.;

which was the same, within the limits of the errors of measurement, as the speed with which light travels in interplanetary space. The coincidence was noticed by Kirchhoff, who was thus the first to discover the important fact that the velocity with which an electric disturbance is propagated along a perfectlyconducting aerial wire is equal to the velocity of light.

In a second memoir published in the same year, Kirchhoff[75] extended the equations of propagation of electric disturbance to the case of three-dimensional conductors.

As in his earlier investigation, he divided the electromotive force at any point into two parts, of which one is the gradient of the electrostatic potential φ, and the other is the derivate with respect to the time (with sign reversed) of a vectorpotential a; so that if i denote the current and k the specific conductivity, Ohm's law is expressed by the equation

�
=
�
(
�
2
g
r
a
d
 
�
−
�
˙
)
{\displaystyle i=k(c^{2}\mathrm {grad} \ \phi -{\dot {\mathbf {a} }})}.

Kirchhoff calculated the value of a by aid of Weber's formula for the inductive action of one current element on another; the result is

�
=
∭
�
�
′
 
�
�
′
 
�
�
′
�
3
(
�
.
�
′
)
�
{\displaystyle \mathbf {a} =\iiint {\frac {dx^{\prime }\ dy^{\prime }\ dz^{\prime }}{r^{3}}}(\mathbf {r.i^{\prime }} )\mathbf {r} },

where r denotes the vector from the point (x, y, z), at which a is measured, to any other point (x′, y′, z′) of the conductor, at which the current is i′; and the integration is extended over the whole volume of the conductor. The remaining general equations are the ordinary equation of the electrostatic potential

∇
2
�
+
4
�
�
=
0
{\displaystyle \nabla ^{2}\phi +4\pi \rho =0}

(where ρ denotes the density of electric charge), and the equation of conservation of electricity

∂
�
∂
�
+
d
i
v
 
�
=
0
{\displaystyle {\frac {\partial \rho }{\partial t}}+\mathrm {div} \ \mathbf {i} =0}.

​It will be seen that Kirchhoff's electrical researches were greatly influenced by those of Weber. The latter investigations, however, did not enjoy unquestioned authority; for there was still a question as to whether the expressions given by Weber for the mutual energy of two current elements, and for the mutual energy of two electrons, were to be preferred to the rival formulae of Neumann and Riemann. The matter was examined in 1870 by Helmholtz, in a series of memoirs[76] to which reference has already been made.[77] Helmholtz remarked that, for two elements ds, ds′, carrying currents i, i′, the electrodynamic energy is

�
�
′
(
�
�
.
�
�
′
)
�
{\displaystyle {\frac {ii^{\prime }(\mathbf {ds.ds^{\prime }} )}{r}}},

according to Neumann, and

�
�
′
�
3
(
�
.
�
�
)
(
�
.
�
�
′
)
{\displaystyle {\frac {ii^{\prime }}{r^{3}}}(\mathbf {r.ds} )(\mathbf {r.ds^{\prime }} )},

according to Weber; and that these expressions differ from each other only by the quantity

�
�
′
�
�
�
�
′
�
{
−
cos
⁡
(
�
�
.
�
�
′
)
+
cos
⁡
(
�
.
�
�
)
cos
⁡
(
�
.
�
�
′
)
}
{\displaystyle {\frac {ii^{\prime }dsds^{\prime }}{r}}\{-\cos(ds.ds^{\prime })+\cos(r.ds)\cos(r.ds^{\prime })\}},

or
�
�
′
�
�
�
�
′
�
2
�
�
�
 
�
�
′{\displaystyle ii^{\prime }dsds^{\prime }{\frac {d^{2}r}{ds\ ds^{\prime }}}};
since this vanishes when integrated round either circuit, the two formulae give the same result when applied to entire currents. A general formula including both that of Neumann and that of Weber is evidently

�
�
′
(
�
�
.
�
�
′
)
�
+
�
�
�
′
�
2
�
�
�
 
�
�
′
 
�
�
 
�
�
′{\displaystyle {\frac {ii^{\prime }(\mathbf {ds.ds^{\prime }} )}{r}}+kii^{\prime }{\frac {d^{2}r}{ds\ ds^{\prime }}}\ ds\ ds^{\prime }},

where k denotes an arbitrary constant.[78]

Helmholtz's result suggested to Clausius[79] a new form for the law of force between electrons; namely, that which is ​obtained by supposing that two electrons of charges e, e′, and velocities v, v′, possess electrokinetic energy of amount

�
�
′
(
�
.
�
′
)
�
+
�
�
�
′
�
2
�
�
�
 
�
�
′
�
�
′{\displaystyle {\frac {ee^{\prime }(\mathbf {v.v^{\prime }} )}{r}}+kee^{\prime }{\frac {d^{2}r}{ds\ ds^{\prime }}}vv^{\prime }}

Subtracting from this the mutual electrostatic potential energy, which is ee′c2/r, we may write the mutual kinetic potential of the two electrons in the form

�
�
′
�
(
�
˙
�
˙
′
+
�
˙
�
˙
′
+
�
˙
�
˙
′
−
�
2
)
+
�
�
�
′
�
2
�
�
�
 
�
�
′
�
�
′{\displaystyle {\frac {ee^{\prime }}{r}}({\dot {x}}{\dot {x}}^{\prime }+{\dot {y}}{\dot {y}}^{\prime }+{\dot {z}}{\dot {z}}^{\prime }-c^{2})+kee^{\prime }{\frac {d^{2}r}{ds\ ds^{\prime }}}vv^{\prime }}

where (x, y, z) denote the coordinates of e, and (x′, y′, z′) those of e′.

The unknown constant k has clearly no influence so long as closed circuits only are considered: if k be replaced by zero, the expression for the kinetic potential becomes

�
�
′
�
(
�
˙
�
˙
′
+
�
˙
�
˙
′
+
�
˙
�
˙
′
−
�
2
)
{\displaystyle {\frac {ee^{\prime }}{r}}({\dot {x}}{\dot {x}}^{\prime }+{\dot {y}}{\dot {y}}^{\prime }+{\dot {z}}{\dot {z}}^{\prime }-c^{2})}

which, as will appear later, closely resembles the corresponding expression in the modern theory of electrons.

Clausius' formula has the great advantage over Weber's, that it does not compel us to assume equal and opposite velocities for the vitreous and resinous charges in an electric current; on the other hand, Clausius' expression involves the absolute velocities of the electrons, while Weber's depends only on their relative motion; and therefore Clausius' theory requires the assumption of a fixed aether in space, to which the velocities v and v′ may be referred.

When the behaviour of finite electrical systems is predicted from the formulae of Weber, Riemann, and Clausius, the three laws do not always lead to concordant results. For instance, if a circular current be rotated with constant angular velocity round its axis, according to Weber's law there would be a development of free electricity on a stationary conductor in the neighbourhood; whereas, according to Clausius' formula there would be no induction on a stationary body, but electrification ​would appear on a body turning with the circuit as if rigidly connected with it. Again,[80] let a magnet be suspended within a hollow metallic body, and let the hollow body be suddenly charged or discharged; then, according to Clausius' theory, the magnet is unaffected; but according to Weber's and Riemann's theories it experiences an impulsive couple. And again, if an electrified disk be rotated in its own plane, under certain circumstances a steady current will be induced in a neighbouring circuit according to Weber's law, but not according to the other formulae.

An interesting objection to Clausius' theory was brought forward in 1879 by Fröhlich[81]—namely, that when a charge of free electricity and a constant electric current are at rest relatively to each other, but partake together of the translatory motion of the earth in space, a force should act between them if Clausius' law were true. It was, however, shown by Budde[82] that the circuit itself acquires an electrostatic charge, partly as a result of the same action which causes the force on the external conductor, and partly as a result of electrostatic induction by the charge on the external conductor; and that the total force between the circuit and external conductor is thus reduced to zero.[83]


We have seen that the discrimination between the different laws of electrodynamic force is closely connected with the question whether in an electric current there are two kinds of electricity moving in opposite directions, or only one kind moving in one direction. On the unitary hypothesis, that the ​current consists in a transport of one kind of electricity with a definite velocity relative to the wire, it might be expected that a coil rotated rapidly about its own axis would generate a magnetic field different from that produced by the same coil at rest. Experiments to determine the matter were performed by A. Föppl[84] and by E. L Nichols and W. S. Franklin,[85] but with negative results. The latter investigators found that the velocity of electricity must be such that the quantity conveyed past a specified point in a unit of time, when the direction of the current was that in which the coil was travelling, did not differ from that transferred when the current and coil were moving in opposite directions by as much as one part in ten million, even when the velocity of the wire was 9096 cm./sec. They considered that they would have been able to detect a change of deflexion due to the motion of the coil, even though the velocity of the current had been considerably greater than a thousand million metres per second.


During the decades in the middle of the century consider- able progress was made in the science of thermo-electricity, whose beginnings we have already described.[86] In Faraday's laboratory note-book, under the date July 28th, 1836, we read[87]:—"Surely the converse of thermo-electricity ought to be obtained experimentally. Pass current through a circuit of antimony and bismuth."

Unknown to Faraday, the experiment here indicated had already been made, although its author had arrived at it by a different train of ideas. In 1834 Jean Charles Peltier[88] (b. 1785, d. 1845) attempted the task, which was afterwards performed with success by Joule,[89] of measuring the heat evolved by the passage of an electric current through a conductor. He found that a current produces in a homogeneous conductor an elevation ​of temperature, which is the same in all parts of the conductor where the cross-section is the same; but he did not succeed in connecting the thermal phenomena quantitatively with the strength of the current—a failure which was due chiefly to the circumstance that his attention was fixed on the rise of temperature rather than on the amount of the heat evolved. But incidentally the investigation led to an important discovery—namely, that when a current was passed in succession through two conductors made of dissimilar metals, there was an evolution of heat at the junction; and that this depended on the direction of the current; for if the junction was heated when the current flowed in one sense, it was cooled when the current flowed in the opposite sense. This Peltier effect, as it is called, is quite distinct from the ordinary Joulian liberation of heat, in which the amount of energy set free in the thermal form is unaffected by a reversal of the current; the Joulian effect is, in fact, proportional to the square of the current-strength, while the Peltier effect is proportional to the current-strength directly. The Peltier heat which is absorbed from external sources when a current i flows for unit time through a junction from one metal B to another metal A may therefore be denoted by

∏
�
�
(
�
)
.
�
{\displaystyle \textstyle \prod _{B}^{A}(T)\mathbf {.} i},

where T denotes the absolute temperature of the junction. The function 
∏
�
�
(
�
)
{\displaystyle \textstyle \prod _{B}^{A}(T)} is found to be expressible as the difference of two parts, of which one depends on the metal A only, and the other on the metal B only; thus we can write

∏
�
�
(
�
)
=
∏
�
(
�
)
−
∏
�
(
�
)
{\displaystyle \textstyle \prod _{B}^{A}(T)=\textstyle \prod _{A}(T)-\textstyle \prod _{B}(T)}.

In 1851 a general theory of thermo-electric phenomena was constructed on the foundation of Seebeck's[90] and Peltier's discoveries by W. Thomson.[91] Consider a circuit formed of two ​metals, A and B, and let one junction be maintained at a slightly higher temperature (T + δT) than the temperature T of the other junction. As Seebeck had shown, a thermo-electric current will be set up in the circuit. Thomson saw that such a system might be regarded as a heat-engine, which absorbs a certain quantity of heat at the hot junction, and convorts part of this into electrical energy, liberating the rest in the form of heat at the cold junction. If the Joulian evolution of heat be neglected, the process is reversible, and must obey the second law of thermodynamics; that is, the sum of the quantities of heat absorbed, cach divided by the absolute temperature et which it is absorbed, must vanish. Thus we have

∏
�
�
(
�
+
�
�
)
�
+
�
�
−
∏
�
�
(
�
)
�
=
0
{\displaystyle {\frac {\textstyle \prod _{B}^{A}(T+\delta T)}{T+\delta T}}-{\frac {\textstyle \prod _{B}^{A}(T)}{T}}=0};

so the Peltier effect 
∏
�
�
(
�
)
{\displaystyle \textstyle \prod _{B}^{A}(T)} must be directly proportional to the absolute temperature T. This result, however, as Thomson well knew, was contradicted by the observations of Cumming, who had shown that when the temperature of the hot junction is gradually increased, the electromotive force rises to a maximum value and then decreases. The contradiction led Thomson to predict the existence of a hitherto unrecognized thermo-electric phenomenon-namely, a reversible absorption of heat at places in the circuit other than the junctions. Suppose that a current flows along a wire which is of the same metal throughout, but varies in temperature from point to point. Thomson showed that heat must be liberated at some points and absorbed at others, so as either to accentuate or to diminish the differences of temperature at the different points of the wire. Suppose that the heat absorbed from external sources when unit electric charge passes from the absolute temperature T to the temperature (T + δT) in a metal A is denoted by SA(T).δT. The thermodynamical equation now takes the corrected form

∏
�
�
(
�
+
�
�
)
�
+
�
�
−
∏
�
�
(
�
)
�
+
{
�
�
(
�
)
−
�
�
(
�
)
}
�
�
�
=
0
{\displaystyle {\frac {\textstyle \prod _{B}^{A}(T+\delta T)}{T+\delta T}}-{\frac {\textstyle \prod _{B}^{A}(T)}{T}}+\{S_{B}(T)-S_{A}(T)\}{\frac {\delta T}{T}}=0}.

​Since the metals A and B are quite independent, this gives
∏
�
(
�
+
�
�
)
�
+
�
�
−
∏
�
(
�
)
�
−
�
�
(
�
)
�
�
�
=
0
{\displaystyle {\frac {\textstyle \prod _{A}(T+\delta T)}{T+\delta T}}-{\frac {\textstyle \prod _{A}(T)}{T}}-S_{A}(T){\frac {\delta T}{T}}=0},

or
�
�
(
�
)
=
�
�
�
�
{
∏
�
(
�
)
�
}
{\displaystyle S_{A}(T)=T{\frac {d}{dT}}\left\{{\frac {\textstyle \prod _{A}(T)}{T}}\right\}}.
This equation connects Thomson's "specific heat of electricity" SA(T) with the Peltier effect.

In 1870 P. G. Tait[92] found experimentally that the specific heat of electricity in pure metals is proportional to the absolute temperature. We may therefore write 
�
�
(
�
)
=
�
�
�
{\displaystyle S_{A}(T)=\rho _{A}T}, where 
�
�
{\displaystyle \rho _{A}}, denotes a constant characteristic of the metal 
�
A. The thermodynamical equation then becomes

�
�
�
{
∏
�
(
�
)
�
}
=
�
�
{\displaystyle {\frac {d}{dT}}\left\{{\frac {\textstyle \prod _{A}(T)}{T}}\right\}=\sigma _{A}},

or
∏
�
(
�
)
=
�
�
�
+
�
�
�
2
{\displaystyle \textstyle \prod _{A}(T)=\pi _{A}T+\sigma _{A}T^{2}}.
where πA denotes another constant characteristic of the metal. The chief part of the Peltier effect arises from the term πAT.

By the investigations which have been described in the present chapter, the theory of electric currents was considerably advanced in several directions. In all these researches, however, attention was fixed on the conductor carrying the current as the seat of the phenomenon. In the following period, interest was centred not so much on the conductors which carry charges and currents, as on the processes which take place in the dielectric media around them.
